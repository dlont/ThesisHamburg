In the least-square method the optimal values of parameters providing the best agreement of theoretical predictions with the data are estimated minimising the difference between data and theory. Given theoretical predictions, $t_i\left( \mathbf{a} \right)$, in the cross section bin $i$ which depend on the vector of parameters of interest $\mathbf{a}$, the outcome of the measurement, $m_i$, can be modelled as follows~\cite{Stump:2001gu,Botje:2001fx}:
\begin{equation}
 m_i = t_i\left( \mathbf{a} \right) + \varepsilon_{i} \sigma_{i,\text{uncor}} + \sum_{\mu=1}^{K}{b_{i,\mu}\sigma_{i,\text{cor}}^\mu}, \qquad i=1\ldots N_\text{bins},
\end{equation}
where $\sigma_{i,\text{uncor}}$ is an estimate of total uncorrelated uncertainty for the cross section measuremet and $\varepsilon_{i}$ is a random normally distributed variable with mean value $\left\langle \varepsilon_{i}\right\rangle = 0$ and variance $\text{Var}\left( \varepsilon_{i}\right) = 1$; $\sigma_{i,\text{cor}}^\mu$ and $b_{i,\mu}$ represent the correlated uncertainty from sources $\mu$ and the corresponding systematic shift, respectively. It is assumed that the systematic shifts can also be modelled by normally distributed random variables with zero mean and unit variance. In order to take into account proportionality of the systematic uncertainties to the central value\footnote{Most of the systematic uncertainties in this analysis e.g. absolute normalisation uncertainty or acceptance correction uncertainty to good approximation are proportional to the central value of the measured cross section.}, the corresponding uncertainty components are expressed as $\sigma_{i,\text{cor}}^\mu = \gamma_{i,\mu}m_i$, where $\gamma_{i,\mu}=1/\left( {m_i\sigma_{i,\text{cor}}^\mu}\right) \frac{\partial m_i}{\partial b_{i,\mu}}$ quantifies the sensitivity of the measurement $i$ to the systematic source $\mu$. The statistical uncertainty, however, is assumed to scale propotionaly to the square root of number of events. The difference between data and theoretical predictions is evaluated using the weighted squared norm. Taking everything into account the $\chi^2$-function for statistically uncorrelated measurements is defined as:
\begin{equation}
 \chi^2 = \sum_i{ \frac{\left( m_i-t_i-\sum_{\mu}{\gamma_{i,\mu} m_i b_\mu} \right)^2 }{ \left( \sigma_{\text{stat},i}m_i \right)^2 + \left( \sigma_{i,\text{uncor}}\right)^2 } } + \sum_{\mu}{b_\mu^2}
 \label{eq:chi2uncorr}
\end{equation}
The last term in Eq.~\eqref{eq:chi2uncorr} represents the penalty for the nuissance parameters. 

Agreement between data and theory is estimated using the following ansatz for the $\chi^2$-function~\cite{Aaron:2009aa}:
%\begin{equation}
% \chi^2\left( \mathbf{m},\mathbf{b}\right) = \sum_{i}{\frac{\left[ m^i-\Sigma_j{\gamma^i_jm^ib_j-\mu^i}\right]^2 }{\left( \delta_{i,\text{stat}}\mu^i\right)^2 + \left( \delta_{i,\text{uncor}}\mu^i\right)^2 }} + \sum_{j}{b_j^2}
% \label{eq:chi2uncor}
%\end{equation}
\begin{equation}
 \chi^2\left( \mathbf{m},\mathbf{b}\right) = \sum_{ij}{\left( m^i -\sum_{l}{\Gamma_l^i\left( m^i\right)b_l - \mu^i }\right) C^{-1}_{ij,\text{stat}} \left( m^j -\sum_{l}{\Gamma_l^j\left( m^j\right)b_l - \mu^j }\right) } + \sum_{j}{b_j^2},
 \label{eq:chi2corr}
\end{equation}
where $\mu^i$ is the measured central value of the cross section in bin $i$, the $\Gamma_i^l$ quantifies the sensitivity of the measurement $i$ to the correlated systematic source of uncertainty $l$, the $C^{-1}_{ij,\text{stat}}$ is covariance matrix for the measured data points. The parameter vectors $\mathbf{m}$ and $\mathbf{b}$ represent the theoretical predictions for the point $i$ and systematic uncertainties, respectively. The predictions $\mathbf{m}\left( \mathbf{a},\asz\right)$ are usually treated as functions of the proton PDF parameters, $\mathbf{a}$,  and \asz. The determination procedure of the parametrisation of the pPDFs and \as that best fit the data is based on the numerical minimisation of the $\chi^2$ function with respect to the free parameters. The nuisance parameters $\mathbf{b}$ introduced in the $\chi^2$ definition are fitted together with other parameters in order to consistently take into account systematic uncertainties correlated across measurement points.

An efficient code~\cite{herafitter} for QCD analysis...  The \herafitter program is a tool originally developed for least-square fits of the proton PDFs. The other details concerning the $\chi^2$-function definition can be found in the \herafitter manual~\cite{herafitter:2014:manual}. The \herafitter~\cite{Aaron:2009aa,Aaron:2009kv} program package was used for the \as extraction. The main features of the \herafitter framework are outlined below.

The predictions for the inclusive-jet cross sections were calculated using the \nlojet program with the \fastnlo interface. The setting for the NLO pQCD calculations were described in detail in Section~\ref{sec:nlopredictions} and are briefly summarised in the Table~\ref{tab:nlosettings}.
\begin{table}[h]
\centering
\begin{tabular}{l|c}
Parameter  & Default setup \\ 
\hline \hline proton PDF set & \herapdf1.5 (NLO) \\
\hline renormaliastion scale & $\mu_R^2=\qsq + \etjetb^2$ \\ 
\hline factorisation scale          & $\mu_F^2=\qsq $ \\ 
\hline number of active flavours    & $n_f = 5 $ \\ 
\end{tabular} 
\caption{Summary of the theory settings used for the calculations for the \as determination.}
\label{tab:nlosettings}
\end{table}
The NLO predictions were corrected for electroweak and non-perturbative effects using the MC models as described in Sections~\ref{electroweak hadronisation}.

These setting define the, so-called ``central-fit''. The value of the strong coupling determined with this setup is used as a reference for the studies of the sensitivity of the extracted \asz to the variation of the theory parameters that will be discussed in a section devoted to the treatment of systematic uncertainties (see Section~\ref{subsec:assystematics}).
